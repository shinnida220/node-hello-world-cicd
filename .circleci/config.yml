# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

commands:
  sample_smoke_test:
    steps:
      - run: apk add --update curl
      - run:
          name: Sample smoke test
          command: |
            URL="https://blog.udacity.com/"
            if curl -s --head ${URL}
            then
              return 0
            else
              return 1
            fi

  destroy_infrastrcuture:
    steps:
      - run:
          name: Destroy Infrastructure
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7} --region us-east-1

# Define a job to be invoked later in a workflow.
jobs:
  create_infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create CloudFormation Stack
          command: |
            aws cloudformation deploy \
              --template-file template.yml \
              --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7} \
              --region us-east-1

  configure_infrastructure:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["49:01:d4:24:62:d9:50:6b:af:73:ba:0d:9b:2e:f4:0c"]
      - run:
          name: Install Dependencies (Ansible)
          command: |
            apk add --update ansible
      - run:
          name: Confgure Server
          command: |
            ansible-playbook -i inventory.txt main-remote.yml

  smoke_test:
    docker:
      - image: amazon/aws-cli #alpine:latest
    steps:
      - run:
          name: Simulate error
          command: |
            return 1 #simmulate returning a non zero (0) exit code so the job will fail
      - destroy_infrastrcuture

  # Create new S3 BUCKET
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="ei-udacitybucket-${CIRCLE_WORKFLOW_ID:0:7}" \
            --region us-east-1
      # upload index file of the current directory to the S3 bucket
      - run: aws s3 cp index.html s3://ei-udacitybucket-${CIRCLE_WORKFLOW_ID:0:7}

  # Job to fetch and save the pipeline ID (bucket ID) responsible for the last release.
  # In this job, we are saving the bucket ID to a file and persist the file to the workspace for other jobs to access.
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and Save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - textfile.txt

  # Write a job named promote_to_production that executes our cloudfront.yml CloudFormation template used in the manual steps
  # Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
              --template-file cloudfront.yml \
              --stack-name production-distro \
              --parameter-overrides PipelineID="ei-udacitybucket-${CIRCLE_WORKFLOW_ID:0:7}" \
              --region us-east-1

  # This job uses the pipeline ID to destroy the previous production version's S3 bucket
  # and CloudFormation stack.
  # To achieve this, you need to retrieve from the workspace the file where the previous Pipeline ID was stored.
  # Destroy the previous production version's S3 bucket and CloudFormation stack.
  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous S3 bucket and CloudFormation stack.
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive
            aws cloudformation delete-stack --stack-name production-distro --region us-east-1

# Invoke jobs via workflows
workflows:
  my-workflow:
    jobs:
      # - create_infrastructure
      # # - configure_infrastructure
      # - smoke_test:
      #     requires:
      #       - create_infrastructure
      - create_and_deploy_front_end
      - promote_to_production:
          requires:
            - create_and_deploy_front_end
      - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production
